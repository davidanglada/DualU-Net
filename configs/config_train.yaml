dataset:
  train:
    name: consep
    root: "/mnt/work/users/david.anglada/datasets/consep_coco/"  # Path to the training dataset
    fold: Train
    num_classes: 4                   # Fold to use for training
  val:
    name: consep
    root: "/mnt/work/users/david.anglada/datasets/consep_coco/"    # Path to the validation dataset
    fold: Test
    num_classes: 4                   # Fold to use for validation

loader:
  train:
    shuffle: True
    batch_size: 4
    num_workers: 1
    drop_last: False
  val:
    shuffle: False
    batch_size: 1
    num_workers: 1
    drop_last: False

optimizer:
  lr_base: 0.0002
  epochs: 100
  weight_decay: 0.0001
  lr_drop_steps:
    - 70
    - 90
  lr_drop_factor: 0.1
  lr_auto_scale: True

distributed: True

training:
  weight_dice: 1.0
  weight_dice_b: 1.0
  weight_ce: 1.0
  weight_mse: 1.0
  ce_weights: ./ce_weights_consep_Train_b10.npy
  sigma: 5
  th: 0.15

transforms:
  normalize:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  augmentations:
    - name: "hflip"
      p: 0.5
    - name: "vflip"
      p: 0.5
    - name: "rotate90"

model:
  encoder_name: resnext50_32x4d 
  classes_s: 4                   
  classes_c: 1                    
  encoder_weights: imagenet      
  decoder_channels: [256, 128, 64, 32, 16] 
  decoder_use_batchnorm: True

evaluation:
  thresholds: [0.5]
  max_pair_distance: 12
  interval: 10

experiment:
  wandb: True
  project: "DualU-Net_uncert_loss"
  name: "resnext_consep" 
  wandb_group: "train"
  seed: 42
  output_dir: /mnt/work/users/david.anglada/dualunet/checkpoints/
  output_name: "resnext_consep" 
  resume: False
